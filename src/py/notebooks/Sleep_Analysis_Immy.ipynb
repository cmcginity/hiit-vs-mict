{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980123b-3e9a-4f92-8869-63fbf4c03ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Google Drive Access:\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# Import packages for connecting to Google Drive\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "# from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "# CHANGE PATH NAME to where the service account credential is on your computer.\n",
    "credentials_path = '/Users/imogengardiner/Documents/exercise_credential.json'\n",
    "\n",
    "# REPLACE FOLDER_ID with the folder in Google Drive you are interested in importing data from.\n",
    "    # Instructions: Search online for the HIIT and Endurance Study shared google drive. Navigate to the folder with data you are interested in. \n",
    "    # Look at the web URL. Replace 'folder_id' with the end of the URL.\n",
    "    # Example for getting Polar Data: HIIT and Endurance Study Drive > Data > data > workout folder. The workout folder URL is https://drive.google.com/drive/folders/1a9Bmg89_9m9BaYLsLw52PS_m07FQ7CtZ.\n",
    "    # Notice how the end of the web URL is the folder_id.\n",
    "folder_id = '1PjDaMLxn3QvYqICxCxK5PF2-yhh8sNoa'\n",
    "\n",
    "# Authenticate with Google Drive using service account credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(credentials_path, scopes=['https://www.googleapis.com/auth/drive'])\n",
    "drive_service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "# Get files\n",
    "def get_file_ids_from_dir(parent_id):\n",
    "    # drive_service = setup_drive()\n",
    "    results = drive_service.files().list(\n",
    "        corpora='drive',\n",
    "        driveId='0AB6End4Uf7P-Uk9PVA', # if you search for the HIIT and Endurance Study shared google drive, this ID is taken from the end of the pathname: https://drive.google.com/drive/folders/0AB6End4Uf7P-Uk9PVA\n",
    "        q=f\"'{parent_id}' in parents\",\n",
    "        includeItemsFromAllDrives=True,\n",
    "        supportsAllDrives=True\n",
    "    ).execute()\n",
    "    files = results.get('files', [])\n",
    "    if not files:\n",
    "        raise Exception(f\"Folder {parent_id} has no files!\")\n",
    "    # id_name = [{x['name'] : x['id']} for x in files]\n",
    "    id_name = {}\n",
    "    for x in files:\n",
    "        id_name[x['name']] = x['id']\n",
    "    return id_name\n",
    "\n",
    "def load_data_from_drive(_drive_service, file_id):\n",
    "    request = _drive_service.files().get_media(fileId=file_id)\n",
    "    io_buffer = io.BytesIO()\n",
    "    downloader = MediaIoBaseDownload(io_buffer, request)\n",
    "    done = False\n",
    "    while done is False:\n",
    "        status, done = downloader.next_chunk()\n",
    "    io_buffer.seek(0)\n",
    "    df = pd.read_csv(io_buffer, parse_dates=['_realtime','_time'])\n",
    "    return df\n",
    "\n",
    "# Get file names from folder\n",
    "fileids = get_file_ids_from_dir(folder_id)\n",
    "print(fileids)\n",
    "\n",
    "dfsl_list = []\n",
    "for fname, fid in fileids.items():\n",
    "    dfsl = load_data_from_drive(drive_service, fid)\n",
    "    dfsl_list.append(dfsl)\n",
    "\n",
    "print(dfsl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df33b4-8bc1-43e0-9353-c7a4f9e0ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer code from 007 analysis and loop through every file in the sl/Fitbit folder, and create plots for each participant:\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for file in dfsl_list:\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Store the DataFrame in the dictionary with the file name as the key\n",
    "    dfs[file[:3]] = df\n",
    "\n",
    "# Drop unnecessary columns from the DataFrame\n",
    "for i in range(len(dfsl_list)):\n",
    "    columns_to_remove = ['device', 'start_date', 'end_date', 'start_time', 'end_time', '_time', 'myphd_id', 'target_hr_45', 'target_hr_55', 'target_hr_70', 'target_hr_90', 'ppt_id', 'moy_abbr', 'tag', 'datatype', 'sourcetype', 'dname',\n",
    "                    'myphd_date_shift']\n",
    "    dfsl_list[i] = dfsl_list[i].drop(columns=columns_to_remove)\n",
    "    \n",
    "dfsl_list = dfsl_list[dfsl_list['enrollment_status']=='Completed']\n",
    "                         \n",
    "\n",
    "print(dfsl_list.head())\n",
    "\n",
    "# Adjust the values to reflect seconds (rather than decaseconds)\n",
    "dfsl_list_004['value'] = dfsl_list_004['value']*10\n",
    "\n",
    "# Rename value to seconds\n",
    "dfsl_list_004 = dfsl_list_004.rename(columns={'value': 'seconds'})\n",
    "\n",
    "print(dfsl_list_004.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9d3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700ad0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
