{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8890c6e-329f-4886-8934-709ac8b8eb00",
   "metadata": {},
   "source": [
    "# CPX / CTRU Data checks\n",
    "### Last update June 2, 2024\n",
    "### Aubrey Roberts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "ea775398-43fb-49db-b4fa-6357600b08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40669d-4c0f-4e78-b6e7-343c49deb7f9",
   "metadata": {},
   "source": [
    "## Single use case: how to extract VO2 peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "075ccc1b-a313-43ee-8d73-0390c3237eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>Max</th>\n",
       "      <th>date</th>\n",
       "      <th>last_name</th>\n",
       "      <th>timepoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>44.4</td>\n",
       "      <td>8/31/2023</td>\n",
       "      <td>Trotsyuk</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_id   Max       date last_name timepoint\n",
       "0        30  44.4  8/31/2023  Trotsyuk  baseline"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify data of interest \n",
    "path = \"/Users/aubreykr/Google Drive/Shared drives/HIIT and Endurance Study/Data/data/cpet_bxb/shc_vo2-max/baseline/30_scr_bl_ep_arm_1_bl_cpx_raw_data.xlsx\"\n",
    "\n",
    "# Read in first CPX sheet (name, test date)\n",
    "df = pd.read_excel(path)\n",
    "df1 = pd.DataFrame(df)\n",
    "\n",
    "test_date=df1.columns[4]\n",
    "first_name = df1.iat[1,1]\n",
    "last_name = df1.iat[0,1]\n",
    "\n",
    "# Extract record_id from path name\n",
    "string = str.split(path,'/')[11]\n",
    "record_id = str.split(string,'_')[0]\n",
    "timepoint = str.split(path,'/')[10]\n",
    "\n",
    "# Print participant\n",
    "#record_id, first_name, last_name, timepoint, test_date\n",
    "\n",
    "# Read the second sheet (for VO2 peak)\n",
    "df2 = pd.read_excel(path, sheet_name='Results', skiprows=13)\n",
    "df2 = df2[df2['Parameter'] == 'VO2/Kg'][['Max']]\n",
    "\n",
    "df2['date'] = test_date\n",
    "df2['record_id'] = record_id\n",
    "df2['last_name'] = last_name\n",
    "df2['timepoint'] = timepoint\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "col = [\"record_id\"]\n",
    "df2 = df2[col + [x for x in df2.columns if x not in col]]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da19c94-171d-4dbf-8644-fb26c6cdec98",
   "metadata": {},
   "source": [
    "## Define function for getting VO2 peak from CPX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "91ac775f-e18b-4e6a-90d4-f5022df7e6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>Max</th>\n",
       "      <th>date</th>\n",
       "      <th>last_name</th>\n",
       "      <th>timepoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>44.4</td>\n",
       "      <td>8/31/2023</td>\n",
       "      <td>Trotsyuk</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_id   Max       date last_name timepoint\n",
       "0        30  44.4  8/31/2023  Trotsyuk  baseline"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_file(path):\n",
    "    # Read in first CPX sheet (name, test date)\n",
    "    df = pd.read_excel(path)\n",
    "    df1 = pd.DataFrame(df)\n",
    "\n",
    "    test_date = df1.columns[4]\n",
    "    first_name = df1.iat[1,1]\n",
    "    last_name = df1.iat[0,1]\n",
    "\n",
    "    # Extract record_id and timepoint from path name\n",
    "    string = str.split(path, '/')[11]\n",
    "    record_id = str.split(string, '_')[0]\n",
    "    timepoint = str.split(path, '/')[10]\n",
    "\n",
    "    # Read the second sheet (for VO2 peak)\n",
    "    df2 = pd.read_excel(path, sheet_name='Results', skiprows=13)\n",
    "    df2 = df2[df2['Parameter'] == 'VO2/Kg'][['Max']]\n",
    "\n",
    "    df2['date'] = test_date\n",
    "    df2['record_id'] = record_id\n",
    "    df2['last_name'] = last_name\n",
    "    df2['timepoint'] = timepoint\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    col = [\"record_id\"]\n",
    "    df2 = df2[col + [x for x in df2.columns if x not in col]]\n",
    "    df2\n",
    "    \n",
    "    return df2\n",
    "\n",
    "process_file(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3cd25-22f9-4911-aef5-ce8c26f07420",
   "metadata": {},
   "source": [
    "### Get all files in Google Drive folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f34afad6-91cb-4c33-aebb-76543ce779e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your directory\n",
    "import glob\n",
    "import os\n",
    "directory_path = \"/Users/aubreykr/Google Drive/Shared drives/HIIT and Endurance Study/Data/data/cpet_bxb/shc_vo2-max/baseline/\"\n",
    "\n",
    "# Use glob to get a list of all Excel files in the directory\n",
    "file_paths = glob.glob(os.path.join(directory_path, \"*.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0e323-1dcb-411d-a185-779f402e2e19",
   "metadata": {},
   "source": [
    "### Get VO2 peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "aaac914a-1540-4394-a938-c18f0c291b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   record_id   Max       date     last_name timepoint\n",
      "0         84  37.5   2/9/2024       Kononov  baseline\n",
      "1          7  35.9  4/14/2023        ZUSHIN  baseline\n",
      "2         94    37   3/6/2024     Mostafavi  baseline\n",
      "3         83  24.9  1/30/2024       Heather  baseline\n",
      "4          6  30.5  4/13/2023    SASINOWSKI  baseline\n",
      "..       ...   ...        ...           ...       ...\n",
      "63        91  37.2  3/22/2024  Jayachandran  baseline\n",
      "64        86  37.4   3/8/2024       Markley  baseline\n",
      "65        39  38.5   8/1/2023        BARLET  baseline\n",
      "66         5  24.9  5/19/2023            SU  baseline\n",
      "67        19  32.5  6/21/2023         MATTY  baseline\n",
      "\n",
      "[68 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Run this function\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Loop over the list of pathnames and process each file\n",
    "for pathname in file_paths:\n",
    "    try:\n",
    "        result = process_file(pathname)\n",
    "        results_df = pd.concat([results_df, result], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {pathname}: {e}\")\n",
    "\n",
    "# Print or save the consolidated results\n",
    "print(results_df)\n",
    "# Optionally, save to a file\n",
    "# results_df.to_excel('consolidated_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "787434b8-ca8e-4fb1-9d33-5ff6265a7e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['record_id']=pd.to_numeric(results_df[\"record_id\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac69fbe-12e3-45e5-9778-8be419c33800",
   "metadata": {},
   "source": [
    "## Repeat for Endpoint Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b5e0f405-5cb2-4352-a22d-d7eec17d1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/Users/aubreykr/Google Drive/Shared drives/HIIT and Endurance Study/Data/data/cpet_bxb/shc_vo2-max/endpoint/\"\n",
    "\n",
    "# Use glob to get a list of all Excel files in the directory\n",
    "file_paths = glob.glob(os.path.join(directory_path, \"*.xlsx\"))\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "results_df2 = pd.DataFrame()\n",
    "\n",
    "# Loop over the list of pathnames and process each file\n",
    "for pathname in file_paths:\n",
    "    try:\n",
    "        result = process_file(pathname)\n",
    "        results_df2 = pd.concat([results_df2, result], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {pathname}: {e}\")\n",
    "\n",
    "# Print or save the consolidated results\n",
    "results_df2['record_id']=pd.to_numeric(results_df2[\"record_id\"])\n",
    "results_df2 = pd.DataFrame(results_df2)\n",
    "results_df = pd.DataFrame(results_df)\n",
    "\n",
    "# Combine BL and EP dfs\n",
    "vo2_df = pd.concat([results_df, results_df2])\n",
    "\n",
    "#vo2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "d4b7c2b2-258a-44d6-8db9-4a4a48a56599",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vo2_df)\n",
    "vo2_df['record_id']=pd.to_numeric(vo2_df['record_id'])\n",
    "vo2_df = vo2_df.sort_values(by=['record_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6beac125-f2b5-4376-b0a2-4586feeec2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>Max</th>\n",
       "      <th>date</th>\n",
       "      <th>last_name</th>\n",
       "      <th>timepoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>6/20/2023</td>\n",
       "      <td>DELWEL</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35.2</td>\n",
       "      <td>10/17/2023</td>\n",
       "      <td>DELWEL</td>\n",
       "      <td>endpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>28.5</td>\n",
       "      <td>8/3/2023</td>\n",
       "      <td>LEE</td>\n",
       "      <td>endpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "      <td>34.7</td>\n",
       "      <td>4/21/2023</td>\n",
       "      <td>LEE</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>5/19/2023</td>\n",
       "      <td>SU</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>105</td>\n",
       "      <td>38.2</td>\n",
       "      <td>4/30/2024</td>\n",
       "      <td>Duke</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>109</td>\n",
       "      <td>29.8</td>\n",
       "      <td>4/3/2024</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>110</td>\n",
       "      <td>24.1</td>\n",
       "      <td>5/14/2024</td>\n",
       "      <td>Sahai</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>112</td>\n",
       "      <td>37.4</td>\n",
       "      <td>5/13/2024</td>\n",
       "      <td>Polett</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>114</td>\n",
       "      <td>41.1</td>\n",
       "      <td>5/28/2024</td>\n",
       "      <td>Ng</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    record_id   Max        date last_name timepoint\n",
       "50          3    33   6/20/2023    DELWEL  baseline\n",
       "1           3  35.2  10/17/2023    DELWEL  endpoint\n",
       "4           4  28.5    8/3/2023       LEE  endpoint\n",
       "55          4  34.7   4/21/2023       LEE  baseline\n",
       "66          5  24.9   5/19/2023        SU  baseline\n",
       "..        ...   ...         ...       ...       ...\n",
       "43        105  38.2   4/30/2024      Duke  baseline\n",
       "59        109  29.8    4/3/2024    Nelson  baseline\n",
       "17        110  24.1   5/14/2024     Sahai  baseline\n",
       "44        112  37.4   5/13/2024    Polett  baseline\n",
       "38        114  41.1   5/28/2024        Ng  baseline\n",
       "\n",
       "[109 rows x 5 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vo2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5a2fd-18b6-4b05-beb2-0dd6e3d7bf24",
   "metadata": {},
   "source": [
    "## Write to Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "52c7624b-2658-476b-a76c-2b147ceb0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/aubreykr/Desktop/'\n",
    "vo2_df.to_csv(path + 'test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38955900-77ae-4e20-9e88-8307d816fe56",
   "metadata": {},
   "source": [
    "## Code for troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "42d8d09b-9998-478a-8d2f-b131b4206e12",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/aubreykr/Google Drive/Shared drives/HIIT and Endurance Study/Data/data/cpet_bxb/shc_vo2-max/baseline/30_scr_bl_ep_arm_1_ep_cpx_raw_data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[308], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/aubreykr/Google Drive/Shared drives/HIIT and Endurance Study/Data/data/cpet_bxb/shc_vo2-max/baseline/30_scr_bl_ep_arm_1_ep_cpx_raw_data.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df)\n\u001b[1;32m      4\u001b[0m df1\n",
      "File \u001b[0;32m~/anaconda3/envs/ISLP2/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ISLP2/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ISLP2/lib/python3.10/site-packages/pandas/io/excel/_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    481\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ISLP2/lib/python3.10/site-packages/pandas/io/excel/_base.py:1652\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1651\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1652\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1656\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1657\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1658\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1659\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/ISLP2/lib/python3.10/site-packages/pandas/io/excel/_base.py:1525\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1523\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1528\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1529\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ISLP2/lib/python3.10/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/aubreykr/Google Drive/Shared drives/HIIT and Endurance Study/Data/data/cpet_bxb/shc_vo2-max/baseline/30_scr_bl_ep_arm_1_ep_cpx_raw_data.xlsx'"
     ]
    }
   ],
   "source": [
    "path = '/Users/aubreykr/Google Drive/Shared drives/HIIT and Endurance Study/Data/data/cpet_bxb/shc_vo2-max/baseline/30_scr_bl_ep_arm_1_ep_cpx_raw_data.xlsx'\n",
    "df = pd.read_excel(path)\n",
    "df1 = pd.DataFrame(df)\n",
    "df1\n",
    "\n",
    "test_date = df1.columns[4]\n",
    "first_name = df1.iat[1,1]\n",
    "last_name = df1.iat[0,1]\n",
    "\n",
    "# Extract record_id and timepoint from path name\n",
    "string = str.split(path, '/')[11]\n",
    "record_id = str.split(string, '_')[0]\n",
    "timepoint = str.split(path, '/')[10]\n",
    "\n",
    "timepoint, record_id, string\n",
    "\n",
    "# Read the second sheet (for VO2 peak)\n",
    "df2 = pd.read_excel(path, sheet_name='Results', skiprows=13)\n",
    "df2 = df2[df2['Parameter'] == 'VO2/Kg'][['Max']]\n",
    "df2['date'] = test_date\n",
    "df2['record_id'] = record_id\n",
    "df2['last_name'] = last_name\n",
    "df2['timepoint'] = timepoint\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "col = [\"record_id\"]\n",
    "df2 = df2[col + [x for x in df2.columns if x not in col]]\n",
    "df2\n",
    "\n",
    "vo2_df[vo2_df['record_id']==26]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c087bb-ed8c-4e51-8815-150dd1587467",
   "metadata": {},
   "source": [
    "## Compare with REDCap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d2e9e-6407-41e5-a0b5-0d20754a0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import REDCap data for comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
